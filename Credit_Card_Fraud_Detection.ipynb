{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UPLOAD AND DOWNLOAD.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shekharkhandelwal1983/Classification/blob/master/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_VMKS1j1AIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4kLYGy01G0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjA35SxUnn2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url1=\"https://storage.googleapis.com/kaggle-data-sets/8782%2F44566%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1592125319&Signature=JjeI620SKCp3Cp3dMeyczD4trvi%2F7C5sO1iUQp%2BFh4s4dtI5LU2kbieCimBiLvS8E0HZcv%2Bhco%2FyEjMWJx9TzhQ6MP7gsuXObGGGxUJbSfKBLmOpjDXo%2Bn4V3TmA9DF33ZhINT%2FPbc0Y9PL8B7ZR0A3ELURhKtRQz5WChQxMwi5bOSiRDCiRXYk09uTWny7iwzP5gKr%2B3ubiUrdRAQc4ix6Ys%2BU4ySk%2F1uUKdAu3kK6WjMAfH78zIJi64NhiOsjRdFAynLYdjl8%2Bw%2BjaFoDWIOzr3fGkwNQtJGomidX9LcvNfI3iUyKFdkhhfeVFudhwkNqh8i6PYLNFcd8imOYQdw%3D%3D\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkbnjwk21N00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url =\"https://storage.googleapis.com/kaggle-data-sets/310%2F23498%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1592492685&Signature=Uhhy%2B8k2iLkjWgKw3S%2FU4BKN3Aln%2BeVdilrIWjHOmnMZlZ3w%2FBjmTT7Xmw67uJukf0NJkXY0oVFVRwKFwfyc5%2FeHRONE5rVxkCWKNJd1wQg%2F0X3rEFu9h6K8cPfirHP8opOcr7S7TVi0wHCXIaLrptyuXMOYxcsASIP9CprMDk3ZAeW7YVtxxnnFfJv30zFSqZJCimM69rO41DN0hcRRsAHOQYEioBgUJIeXcJ7wkMjee6StGV83haUx8%2FgZl73%2BkkQ7LQtRpoSo%2FFAmCRTvJZ%2FubN7sCCpCFXexkq91aeh5dVYgsnT9HIVxKI%2FtN72J%2B2VEbqEl0vkkVXzhSYXGVw%3D%3D\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn-vhkJN1QNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = 'creditcard.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf-hC9hm1XJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN8QrY_D1kRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name ='creditcard.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSKnfiq1rJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHCQsbiA1vHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile(file_name, 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    zip.printdir() \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaeWAE4YzZUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as suv# linear algebra\n",
        "import pandas as bib # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tap\n",
        "import matplotlib.pyplot as lip\n",
        "import seaborn as bai\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import matplotlib.patches as mpatches\n",
        "import time\n",
        "\n",
        "# Classifier Libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import collections\n",
        "\n",
        "\n",
        "# Other Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC4CWloLzfP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZxbP4Uizk4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
        "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
        "NO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier\n",
        "\n",
        "\n",
        "#TRAIN/VALIDATION/TEST SPLIT\n",
        "#VALIDATION\n",
        "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
        "TEST_SIZE = 0.20 # test size using_train_test_split\n",
        "\n",
        "#CROSS-VALIDATION\n",
        "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
        "\n",
        "\n",
        "\n",
        "RANDOM_STATE = 2018\n",
        "\n",
        "MAX_ROUNDS = 1000 #lgb iterations\n",
        "EARLY_STOP = 50 #lgb early stop \n",
        "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
        "VERBOSE_EVAL = 50 #Print out metric result\n",
        "seed =45\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrr9sAuEzpdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=bib.read_csv('creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLb0lBnjzxaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIJN0SDXzzBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iZtLaK7z_P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDt3wAF0Gxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Credit Card Fraud Detection data -  rows:\",df.shape[0],\" columns:\", df.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyaj3RPk0MWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = df.isnull().sum().sort_values(ascending = False)\n",
        "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
        "bib.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep6FxvGX0Riw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The classes are heavily skewed we need to solve this issue later.\n",
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyMdTozL0XGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isnull().sum().max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1doSxO3R0a8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = df[\"Class\"].value_counts()\n",
        "df1 = bib.DataFrame({'Class': temp.index,'values': temp.values})\n",
        "\n",
        "trace = go.Bar(\n",
        "    x = df1['Class'],y = df1['values'],\n",
        "    name=\"Credit Card Fraud Class - data Imbalance (Not fraud = 0, Fraud = 1)\",\n",
        "    marker=dict(color=\"Red\"),\n",
        "    text=df1['values']\n",
        ")\n",
        "data = [trace]\n",
        "layout = dict(title = 'Credit Card Fraud Class - data Imbalance (Not fraud = 0, Fraud = 1)',\n",
        "          xaxis = dict(title = 'Class', showticklabels=True), \n",
        "          yaxis = dict(title = 'Number of transactions'),\n",
        "          hovermode = 'closest',width=600\n",
        "         )\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWM3N6a0m4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = [\"#0101DF\", \"#DF0101\"]\n",
        "\n",
        "bai.countplot('Class', data=df, palette=colors)\n",
        "lip.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o9SN_jq0pDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot how fraud and non-fraud cases are scattered \n",
        "lip.scatter(df.loc[df['Class'] == 0]['V1'], df.loc[df['Class'] == 0]['V2'], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
        "lip.scatter(df.loc[df['Class'] == 1]['V1'], df.loc[df['Class'] == 1]['V2'], label=\"Class #1\", alpha=0.5, linewidth=0.15,c='r')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ESMRTxp0vct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_0 = df.loc[df['Class'] == 0][\"Time\"]\n",
        "class_1 = df.loc[df['Class'] == 1][\"Time\"]\n",
        "#plt.figure(figsize = (14,4))\n",
        "#plt.title('Credit Card Transactions Time Density Plot')\n",
        "#sns.set_color_codes(\"pastel\")\n",
        "#sns.distplot(class_0,kde=True,bins=480)\n",
        "#sns.distplot(class_1,kde=True,bins=480)\n",
        "#plt.show()\n",
        "hist_data = [class_0, class_1]\n",
        "group_labels = ['Not Fraud', 'Fraud']\n",
        "\n",
        "fig = ff.create_distplot(hist_data, group_labels, show_hist=False, show_rug=False)\n",
        "fig['layout'].update(title='Credit Card Transactions Time Density Plot', xaxis=dict(title='Time [s]'))\n",
        "iplot(fig, filename='dist_only')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR0kHO1j034W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = lip.subplots(ncols=2, figsize=(12,6))\n",
        "s = bai.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=df, palette=\"PRGn\",showfliers=True)\n",
        "s = bai.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=df, palette=\"PRGn\",showfliers=False)\n",
        "lip.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFXctUJK09E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy = df[['Amount','Class']].copy()\n",
        "class_0 = copy.loc[copy['Class'] == 0]['Amount']\n",
        "class_1 = copy.loc[copy['Class'] == 1]['Amount']\n",
        "class_0.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emB4waG_1BqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_1.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExX10EwW1Fmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud = df.loc[df['Class'] == 1]\n",
        "\n",
        "trace = go.Scatter(\n",
        "    x = fraud['Time'],y = fraud['Amount'],\n",
        "    name=\"Amount\",\n",
        "     marker=dict(\n",
        "                color='rgb(238,23,11)',\n",
        "                line=dict(\n",
        "                    color='red',\n",
        "                    width=1),\n",
        "                opacity=0.5,\n",
        "            ),\n",
        "    text= fraud['Amount'],\n",
        "    mode = \"markers\"\n",
        ")\n",
        "data = [trace]\n",
        "layout = dict(title = 'Amount of fraudulent transactions',\n",
        "          xaxis = dict(title = 'Time [s]', showticklabels=True), \n",
        "          yaxis = dict(title = 'Amount'),\n",
        "          hovermode='closest'\n",
        "         )\n",
        "fig = dict(data=data, layout=layout)\n",
        "iplot(fig, filename='fraud-amount')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHQ-HhuF1K-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seperate total data into non-fraud and fraud cases\n",
        "df_nonfraud = df[df.Class == 0] #save non-fraud df observations into a separate df\n",
        "df_fraud = df[df.Class == 1] #do the same for frauds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aazRyNOR1Pi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot of high value transactions($200-$2000)\n",
        "bins = suv.linspace(200, 2000, 100)\n",
        "lip.hist(df_nonfraud.Amount, bins, alpha=1, density=True, label='Non-Fraud')\n",
        "lip.hist(df_fraud.Amount, bins, alpha=1, density=True, label='Fraud')\n",
        "lip.legend(loc='upper right')\n",
        "lip.title(\"Amount by percentage of transactions (transactions \\$200-$2000)\")\n",
        "lip.xlabel(\"Transaction amount (USD)\")\n",
        "lip.ylabel(\"Percentage of transactions (%)\")\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0vsqW3y1VDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot of transactions in 48 hours\n",
        "bins = suv.linspace(0, 48, 48) #48 hours\n",
        "lip.hist((df_nonfraud.Time/(60*60)), bins, alpha=1,label='Non-Fraud')\n",
        "lip.hist((df_fraud.Time/(60*60)), bins, alpha=0.6,label='Fraud')\n",
        "lip.legend(loc='upper right')\n",
        "lip.title(\"Percentage of transactions by hour\")\n",
        "lip.xlabel(\"Transaction time from first transaction in the dataset (hours)\")\n",
        "lip.ylabel(\"Percentage of transactions (%)\")\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH7fIYaO1bfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot of transactions in 48 hours\n",
        "lip.scatter((df_nonfraud.Time/(60*60)), df_nonfraud.Amount, alpha=0.6, label='Non-Fraud')\n",
        "lip.scatter((df_fraud.Time/(60*60)), df_fraud.Amount, alpha=0.9, label='Fraud')\n",
        "lip.title(\"Amount of transaction by hour\")\n",
        "lip.xlabel(\"Transaction time as measured from first transaction in the dataset (hours)\")\n",
        "lip.ylabel('Amount (USD)')\n",
        "lip.legend(loc='upper right')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyZoXH7J1idj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale \"Time\" and \"Amount\"\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "df['scaled_amount'] = RobustScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['scaled_time'] = RobustScaler().fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "# Make a new dataset named \"df_scaled\" dropping out original \"Time\" and \"Amount\"\n",
        "df_scaled = df.drop(['Time','Amount'],axis = 1,inplace=False)\n",
        "df_scaled.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjacoayH1p1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate pearson correlation coefficience\n",
        "corr = df_scaled.corr() \n",
        "\n",
        "# Plot heatmap of correlation\n",
        "f, ax = lip.subplots(1, 1, figsize=(24,20))\n",
        "bai.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20})\n",
        "ax.set_title(\"Imbalanced Correlation Matrix\", fontsize=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsXDlgwP1ziL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = bai.lmplot(x='V20', y='Amount',data=df, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
        "s = bai.lmplot(x='V7', y='Amount',data=df, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjMx-0nc2EEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = bai.lmplot(x='V1', y='Amount',data=df, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
        "s = bai.lmplot(x='V5', y='Amount',data=df, hue='Class', fit_reg=True,scatter_kws={'s':2})\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOv_D7uh2Tsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = df.columns.values\n",
        "\n",
        "i = 0\n",
        "t0 = df.loc[df['Class'] == 0]\n",
        "t1 = df.loc[df['Class'] == 1]\n",
        "\n",
        "bai.set_style('whitegrid')\n",
        "lip.figure()\n",
        "fig, ax = lip.subplots(8,4,figsize=(16,28))\n",
        "\n",
        "for feature in var:\n",
        "    i += 1\n",
        "    lip.subplot(7,4,i)\n",
        "    bai.kdeplot(t0[feature], bw=0.5,label=\"Class = 0\")\n",
        "    bai.kdeplot(t1[feature], bw=0.5,label=\"Class = 1\")\n",
        "    lip.xlabel(feature, fontsize=12)\n",
        "    locs, labels = lip.xticks()\n",
        "    lip.tick_params(axis='both', which='major', labelsize=12)\n",
        "lip.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWWPsodE2hzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separating dependant variable with independant variables and then dropping it.\n",
        "\n",
        "X = df_scaled.drop(['Class'], axis=1)\n",
        "y = df_scaled['Class']\n",
        "\n",
        "df_scaled.drop('Class', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okdy1GXl2mTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.pipeline import Pipeline # Inorder to avoid testing model on sampled data\n",
        "\n",
        "# Create the training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
        "\n",
        "# # Oversampling and balancing using SMOTE\n",
        "undersam = RandomUnderSampler(random_state=0)\n",
        "oversam = RandomOverSampler(random_state=0)\n",
        "smote = SMOTE(random_state=42)\n",
        "borderlinesmote = BorderlineSMOTE(random_state=42)\n",
        "\n",
        "# resample the training data\n",
        "X_undersam, y_undersam = undersam.fit_sample(X_train,y_train)\n",
        "X_oversam, y_oversam = oversam.fit_sample(X_train,y_train)\n",
        "X_smote, y_smote = smote.fit_sample(X_train,y_train)\n",
        "X_borderlinesmote, y_borderlinesmote = borderlinesmote.fit_sample(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dlKjTbf2zKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import PowerTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7smwE5N209V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt = preprocessing.PowerTransformer(copy=False)\n",
        "trans_X = pt.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izkpG8lW29-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6CvQtYf3Ci-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"X_train Shape : \", X_train.shape)\n",
        "print(\"X_test Shape : \", X_test.shape)\n",
        "\n",
        "y_train_imb = (y_train != 0).sum()/(y_train == 0).sum()\n",
        "y_test_imb = (y_test != 0).sum()/(y_test == 0).sum()\n",
        "print(\"Train data Imbalance: \", y_train_imb)\n",
        "print(\"Test data Imbalance: \", y_test_imb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMhX2PHp3kRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Fit a logistic regression model to our data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtain model predictions\n",
        "y_predicted = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH5djRT73GvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Create true and false positive rates\n",
        "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_predicted)\n",
        "\n",
        "# Calculate Area Under the Receiver Operating Characteristic Curve \n",
        "probs = model.predict_proba(X_test)\n",
        "roc_auc = roc_auc_score(y_test, probs[:, 1])\n",
        "print('ROC AUC Score:',roc_auc)\n",
        "\n",
        "# Obtain precision and recall \n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_predicted)\n",
        "\n",
        "# Calculate average precision \n",
        "average_precision = average_precision_score(y_test, y_predicted)\n",
        "\n",
        "# Define a roc_curve function\n",
        "def plot_roc_curve(false_positive_rate,true_positive_rate,roc_auc):\n",
        "    lip.plot(false_positive_rate, true_positive_rate, linewidth=5, label='AUC = %0.3f'% roc_auc)\n",
        "    lip.plot([0,1],[0,1], linewidth=5)\n",
        "    lip.xlim([-0.01, 1])\n",
        "    lip.ylim([0, 1.01])\n",
        "    lip.legend(loc='upper right')\n",
        "    lip.title('Receiver operating characteristic curve (ROC)')\n",
        "    lip.ylabel('True Positive Rate')\n",
        "    lip.xlabel('False Positive Rate')\n",
        "    lip.show()\n",
        "\n",
        "# Define a precision_recall_curve function\n",
        "def plot_pr_curve(recall, precision, average_precision):\n",
        "    lip.step(recall, precision, color='b', alpha=0.2, where='post')\n",
        "    lip.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "    lip.xlabel('Recall')\n",
        "    lip.ylabel('Precision')\n",
        "    lip.ylim([0.0, 1.05])\n",
        "    lip.xlim([0.0, 1.0])\n",
        "    lip.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
        "    lip.show()\n",
        "\n",
        "# Print the classifcation report and confusion matrix\n",
        "print('Classification report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',confusion_matrix(y_true = y_test, y_pred = y_predicted))\n",
        "\n",
        "# Plot the roc curve \n",
        "plot_roc_curve(false_positive_rate,true_positive_rate,roc_auc)\n",
        "\n",
        "# Plot recall precision curve\n",
        "plot_pr_curve(recall, precision, average_precision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRZL6lVs46E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "# Create the training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(trans_X, y, test_size=.2, random_state=0)\n",
        "\n",
        "# Resample your training data\n",
        "rus = RandomUnderSampler()\n",
        "ros = RandomOverSampler()\n",
        "smote = SMOTE(random_state=5)\n",
        "blsmote = BorderlineSMOTE(random_state=5)\n",
        "\n",
        "X_train_rus, y_train_rus = rus.fit_sample(X_train,y_train)\n",
        "X_train_ros, y_train_ros = ros.fit_sample(X_train,y_train)\n",
        "X_train_smote, y_train_smote = smote.fit_sample(X_train,y_train)\n",
        "X_train_blsmote, y_train_blsmote = blsmote.fit_sample(X_train,y_train)\n",
        "\n",
        "# Fit a logistic regression model to our data\n",
        "rus_model = LogisticRegression().fit(X_train_rus, y_train_rus)\n",
        "ros_model = LogisticRegression().fit(X_train_ros, y_train_ros)\n",
        "smote_model = LogisticRegression().fit(X_train_smote, y_train_smote)\n",
        "blsmote_model = LogisticRegression().fit(X_train_blsmote, y_train_blsmote)\n",
        "\n",
        "y_rus = rus_model.predict(X_test)\n",
        "y_ros = ros_model.predict(X_test)\n",
        "y_smote = smote_model.predict(X_test)\n",
        "y_blsmote = blsmote_model.predict(X_test)\n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_rus))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_true = y_test, y_pred = y_rus))\n",
        "print('*'*25)\n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_ros))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_true = y_test, y_pred = y_ros))\n",
        "print('*'*25)\n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_smote))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_true = y_test, y_pred = y_smote))\n",
        "print('*'*25)\n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_blsmote))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_true = y_test, y_pred = y_blsmote))\n",
        "print('*'*25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utgD-jVP5WCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "bai.set(font_scale=1.5) #Adjust to fit\n",
        "lip.figure(dpi=60)\n",
        "bai.heatmap(cm,annot=True,fmt='d', cmap='winter',linecolor='black',linewidths=0.2)\n",
        "lip.ylabel('True Class')\n",
        "lip.yticks(fontsize = 12)\n",
        "lip.xlabel('Predicted Class')\n",
        "lip.xticks(fontsize=12)\n",
        "lip.suptitle('Confusion Matrix')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdGg0C3sGYol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_smote)\n",
        "bai.set(font_scale=1.5) #Adjust to fit\n",
        "lip.figure(dpi=60)\n",
        "bai.heatmap(cm,annot=True,fmt='d', cmap='winter',linecolor='black',linewidths=0.2)\n",
        "lip.ylabel('True Class')\n",
        "lip.yticks(fontsize = 12)\n",
        "lip.xlabel('Predicted Class')\n",
        "lip.xticks(fontsize=12)\n",
        "lip.suptitle('Confusion Matrix')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpHxUV8GvVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_blsmote)\n",
        "bai.set(font_scale=1.5) #Adjust to fit\n",
        "lip.figure(dpi=60)\n",
        "bai.heatmap(cm,annot=True,fmt='d', cmap='winter',linecolor='black',linewidths=0.2)\n",
        "lip.ylabel('True Class')\n",
        "lip.yticks(fontsize = 12)\n",
        "lip.xlabel('Predicted Class')\n",
        "lip.xticks(fontsize=12)\n",
        "lip.suptitle('Confusion Matrix')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoic2rtHIvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the decision tree model from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create the training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
        "\n",
        "# Fit a logistic regression model to our data\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtain model predictions\n",
        "y_predicted = model.predict(X_test)\n",
        "\n",
        "# Calculate average precision \n",
        "average_precision = average_precision_score(y_test, y_predicted)\n",
        "\n",
        "# Obtain precision and recall \n",
        "precision, recall, _ = precision_recall_curve(y_test, y_predicted)\n",
        "\n",
        "# Plot the recall precision tradeoff\n",
        "plot_pr_curve(recall, precision, average_precision)\n",
        "\n",
        "# Print the classifcation report and confusion matrix\n",
        "print('Classification report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',confusion_matrix(y_true = y_test, y_pred = y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzH3ebwOHZ_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pipeline module we need for this from imblearn\n",
        "from imblearn.pipeline import Pipeline \n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "# Define which resampling method and which ML model to use in the pipeline\n",
        "resampling = BorderlineSMOTE(kind='borderline-2',random_state=0) # instead SMOTE(kind='borderline2') \n",
        "model = DecisionTreeClassifier() \n",
        "\n",
        "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
        "pipeline = Pipeline([('SMOTE', resampling), ('Decision Tree Classifier', model)])\n",
        "\n",
        "# Fit your pipeline onto your training set and obtain predictions by fitting the model onto the test data \n",
        "pipeline.fit(X_train, y_train) \n",
        "y_predicted = pipeline.predict(X_test)\n",
        "\n",
        "# Obtain the results from the classification report and confusion matrix \n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',  confusion_matrix(y_true = y_test, y_pred = y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceuH1cveH1Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pipeline module we need for this from imblearn\n",
        "from imblearn.pipeline import Pipeline \n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "# Define which resampling method and which ML model to use in the pipeline\n",
        "\n",
        "resampling = BorderlineSMOTE(kind='borderline-2',random_state=0) # instead SMOTE(kind='borderline2') \n",
        "model = RandomForestClassifier(n_jobs=NO_JOBS, \n",
        "                             random_state=RANDOM_STATE,\n",
        "                             criterion=RFC_METRIC,\n",
        "                             n_estimators=NUM_ESTIMATORS,\n",
        "                             verbose=False)\n",
        "\n",
        "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
        "pipeline = Pipeline([('SMOTE', resampling), ('Random Forest Classifier', model)])\n",
        "\n",
        "pipeline.fit(X_train, y_train) \n",
        "y_predicted = pipeline.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKoN0OkYIfZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict probabilities\n",
        "probs = model.predict_proba(X_test)\n",
        "\n",
        "print(\"AUC ROC score: \", roc_auc_score(y_test, probs[:,1]))\n",
        "# Obtain the results from the classification report and confusion matrix \n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',  confusion_matrix(y_true = y_test, y_pred = y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IlBmPhEIj2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Random Forest Classifier model from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create the training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
        "\n",
        "# Define the model with balanced subsample\n",
        "model = RandomForestClassifier(bootstrap=True,\n",
        "                               class_weight={0:1, 1:12}, # 0: non-fraud , 1:fraud\n",
        "                               criterion='entropy',\n",
        "                               max_depth=10, # Change depth of model\n",
        "                               min_samples_leaf=10, # Change the number of samples in leaf nodes\n",
        "                               n_estimators=20, # Change the number of trees to use\n",
        "                               n_jobs=-1, \n",
        "                               random_state=5)\n",
        "\n",
        "# Fit your training model to your training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtain the predicted values and probabilities from the model \n",
        "y_predicted = model.predict(X_test)\n",
        "\n",
        "# Calculate probs\n",
        "probs = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate average precision \n",
        "average_precision = average_precision_score(y_test, y_predicted)\n",
        "\n",
        "# Obtain precision and recall \n",
        "precision, recall, _ = precision_recall_curve(y_test, y_predicted)\n",
        "\n",
        "# Plot the recall precision tradeoff\n",
        "plot_pr_curve(recall, precision, average_precision)\n",
        "\n",
        "# Print the roc auc score, the classification report and confusion matrix\n",
        "print(\"auc roc score: \", roc_auc_score(y_test, probs[:,1]))\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Uz6Bh4JCWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_scaled.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XpGaY3MJGKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'Class'\n",
        "predictors = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
        "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
        "       'scaled_amount', 'scaled_time']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzERfNbXJLR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp =bib.DataFrame({'Feature': predictors, 'Feature importance': model.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "lip.figure(figsize = (7,4))\n",
        "lip.title('Features importance',fontsize=14)\n",
        "s = bai.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "lip.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUJMawj8Jds5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pipeline module we need for this from imblearn\n",
        "from imblearn.pipeline import Pipeline \n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "# Define which resampling method and which ML model to use in the pipeline\n",
        "\n",
        "resampling = BorderlineSMOTE(kind='borderline-2',random_state=0) # instead SMOTE(kind='borderline2') \n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
        "pipeline = Pipeline([('SMOTE', resampling), ('AdaBoostClassifier', model)])\n",
        "\n",
        "pipeline.fit(X_train, y_train) \n",
        "y_predicted = pipeline.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eFq32vXKRSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict probabilities\n",
        "probs = model.predict_proba(X_test)\n",
        "\n",
        "print(\"AUC ROC score: \", roc_auc_score(y_test, probs[:,1]))\n",
        "# Obtain the results from the classification report and confusion matrix \n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',  confusion_matrix(y_true = y_test, y_pred = y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n1uHS1-KZv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
        "\n",
        "# Define the model with balanced subsample\n",
        "model = AdaBoostClassifier(random_state=RANDOM_STATE,\n",
        "                         algorithm='SAMME.R',\n",
        "                         learning_rate=0.8,\n",
        "                             n_estimators=NUM_ESTIMATORS)\n",
        "\n",
        "# Fit your training model to your training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Obtain the predicted values and probabilities from the model \n",
        "y_predicted = model.predict(X_test)\n",
        "\n",
        "# Calculate probs\n",
        "probs = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate average precision \n",
        "average_precision = average_precision_score(y_test, y_predicted)\n",
        "\n",
        "# Obtain precision and recall \n",
        "precision, recall, _ = precision_recall_curve(y_test, y_predicted)\n",
        "\n",
        "# Plot the recall precision tradeoff\n",
        "plot_pr_curve(recall, precision, average_precision)\n",
        "\n",
        "# Print the roc auc score, the classification report and confusion matrix\n",
        "print(\"auc roc score: \", roc_auc_score(y_test, probs[:,1]))\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24YeH5HULDcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "bai.set(font_scale=1.5) #Adjust to fit\n",
        "lip.figure(dpi=60)\n",
        "bai.heatmap(cm,annot=True,fmt='d', cmap='winter',linecolor='black',linewidths=0.2)\n",
        "lip.ylabel('True Class')\n",
        "lip.yticks(fontsize = 12)\n",
        "lip.xlabel('Predicted Class')\n",
        "lip.xticks(fontsize=12)\n",
        "lip.suptitle('Confusion Matrix')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jm5Kup1LUMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = bib.DataFrame({'Feature': predictors, 'Feature importance': model.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "lip.figure(figsize = (7,4))\n",
        "lip.title('Features importance',fontsize=14)\n",
        "s = bai.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "lip.show()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj1bvFceLuoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7KQegIALkFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "# Define which resampling method and which ML model to use in the pipeline\n",
        "\n",
        "resampling = BorderlineSMOTE(kind='borderline-2',random_state=0) # instead SMOTE(kind='borderline2') \n",
        "\n",
        "model = CatBoostClassifier(iterations=500,\n",
        "                             learning_rate=0.02,\n",
        "                             depth=12,\n",
        "                             eval_metric='AUC',\n",
        "                             random_seed = RANDOM_STATE,\n",
        "                             bagging_temperature = 0.2,\n",
        "                             od_type='Iter',\n",
        "                             metric_period = VERBOSE_EVAL,\n",
        "                             od_wait=100)\n",
        "\n",
        "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
        "pipeline = Pipeline([('SMOTE', resampling), ('CatBoostClassifier', model)])\n",
        "\n",
        "pipeline.fit(X_train, y_train) \n",
        "y_predicted = pipeline.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyBrRDAzM2qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict probabilities\n",
        "probs = model.predict_proba(X_test)\n",
        "\n",
        "print(\"AUC ROC score: \", roc_auc_score(y_test, probs[:,1]))\n",
        "# Obtain the results from the classification report and confusion matrix \n",
        "\n",
        "print('Classifcation report:\\n', classification_report(y_test, y_predicted))\n",
        "print('Confusion matrix:\\n',  confusion_matrix(y_true = y_test, y_pred = y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULvsqfnM5wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "bai.set(font_scale=1.5) #Adjust to fit\n",
        "lip.figure(dpi=60)\n",
        "bai.heatmap(cm,annot=True,fmt='d', cmap='winter',linecolor='black',linewidths=0.2)\n",
        "lip.ylabel('True Class')\n",
        "lip.yticks(fontsize = 12)\n",
        "lip.xlabel('Predicted Class')\n",
        "lip.xticks(fontsize=12)\n",
        "lip.suptitle('Confusion Matrix')\n",
        "lip.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAclgjmsNHwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = bib.DataFrame({'Feature': predictors, 'Feature importance': model.feature_importances_})\n",
        "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
        "lip.figure(figsize = (7,4))\n",
        "lip.title('Features importance',fontsize=14)\n",
        "s = bai.barplot(x='Feature',y='Feature importance',data=tmp)\n",
        "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
        "lip.show()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDa7Nsv5tthf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "\n",
        "n_inputs = X_train.shape[1]\n",
        "\n",
        "undersample_model = Sequential([\n",
        "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_aPJPsPtyZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKJQtAlzt8Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws32faMVt-FJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_model.fit(X_train, y_train, validation_split=0.2, batch_size=25, epochs=20, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBCIIwAtvmh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_predictions = undersample_model.predict(X_test, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxB2aZtPv5Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_fraud_predictions = undersample_model.predict_classes(X_test, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYzCpi9wB2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "# Create a confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=lip.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, suv.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    lip.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    lip.title(title, fontsize=14)\n",
        "    lip.colorbar()\n",
        "    tick_marks = suv.arange(len(classes))\n",
        "    lip.xticks(tick_marks, classes, rotation=45)\n",
        "    lip.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        lip.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    lip.tight_layout()\n",
        "    lip.ylabel('True label')\n",
        "    lip.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o44NbeCKweli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample_cm = confusion_matrix(y_test, undersample_fraud_predictions)\n",
        "actual_cm = confusion_matrix(y_test, y_test)\n",
        "labels = ['No Fraud', 'Fraud']\n",
        "\n",
        "fig = lip.figure(figsize=(16,8))\n",
        "\n",
        "fig.add_subplot(221)\n",
        "plot_confusion_matrix(undersample_cm, labels, title=\"Random UnderSample \\n Confusion Matrix\", cmap=lip.cm.Reds)\n",
        "\n",
        "fig.add_subplot(222)\n",
        "plot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=lip.cm.Greens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0voNsNExFS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_inputs = X_train.shape[1]\n",
        "\n",
        "oversample_model = Sequential([\n",
        "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVAnQJI6xMjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCloy5_rJvc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_model.fit(X_train, y_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orONVxXKFSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_predictions = oversample_model.predict(X_test, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhjx4JzoKNZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_fraud_predictions = oversample_model.predict_classes(X_test, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCFLkXrcKW1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_smote = confusion_matrix(y_test, oversample_fraud_predictions)\n",
        "actual_cm = confusion_matrix(y_test, y_test)\n",
        "labels = ['No Fraud', 'Fraud']\n",
        "\n",
        "fig = lip.figure(figsize=(16,8))\n",
        "\n",
        "fig.add_subplot(221)\n",
        "plot_confusion_matrix(oversample_smote, labels, title=\"OverSample (SMOTE) \\n Confusion Matrix\", cmap=lip.cm.Oranges)\n",
        "\n",
        "fig.add_subplot(222)\n",
        "plot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=lip.cm.Greens)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}